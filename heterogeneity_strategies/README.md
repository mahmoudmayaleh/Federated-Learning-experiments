# Strategy Resilience Benchmark

This module studies the effect of client heterogeneity on different aggregation strategies. It reuses the Fashion-MNIST simulation stack and compares **FedAvg**, **FedProx**, and **SCAFFOLD** across a range of Dirichlet a values.

## Contents

- `client.py`, `strategy.py` – implementations of the three aggregation rules and their client counterparts.
- `run_server.py`, `run_client.py`, `run_clients_auto.py` – orchestration scripts for launching the coordinator and clients.
- `strategy_results/`, `strategy_figures/` – JSON logs and plots generated by the experiments.
- `plot_*_results.py`, `compare_strategies_summary.py` – visualisation utilities for analysing convergence and accuracy.

## Usage

```bash
python run_server.py --alpha 0.5
python run_client.py --cid 0
```

After all clients finish, generate artefacts:

```bash
python plot_fedavg_results.py
python plot_fedprox_results.py
python plot_scaffold_results.py
python compare_strategies_summary.py
```

The scripts place summaries inside `strategy_figures/` by default.

## Notes

- The default dataset path resolves to `../baseline_federated_training/distributed_data` so that all modules can share the same data splits.
- Adjust hyperparameters such as the number of rounds, client fraction, or optimiser settings directly inside `run_server.py`.
